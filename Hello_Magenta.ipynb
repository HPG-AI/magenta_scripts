{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello Magenta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HPG-AI/magenta_scripts/blob/master/Hello_Magenta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dPkdg9jTjkTd"
      },
      "source": [
        "# Making music with Magenta\n",
        "\n",
        "[Magenta](https://magenta.tensorflow.org/) is a Python library that helps you generate art and music. In this tutorial, we'll talk about the music generation bits in `note_seq` -- how to make your browser sing, and in particular, how to make your browser sing like you!\n",
        "\n",
        "As a library, `note_seq` can help you:\n",
        "- make music using some of the neat abstractions and utilities in the library\n",
        "- use Machine Learning models to generate music."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R122bwRNbTus"
      },
      "source": [
        "# Basic Instructions\n",
        "\n",
        "1. Double click on the hidden cells to make them visible, or select \"View > Expand Sections\" in the menu at the top.\n",
        "2. Hover over the \"`[ ]`\" in the top-left corner of each cell and click on the \"Play\" button to run it, in order.\n",
        "3. Listen to the generated samples.\n",
        "4. Make it your own: copy the notebook, modify the code, train your own models, upload your own MIDI, etc. See the Magenta code on [GitHub](https://github.com/magenta/magenta) for more information!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zJbq5TmtFJUU"
      },
      "source": [
        "# Step 0: First things first!\n",
        "If you're going to use `Magenta`, you need to install it and its dependencies. Some of the later examples will also download other dependencies (such as models and checkpoints)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "PfRDVhNs3UFx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7b6f904-377f-49bf-f53b-26a727c0fce2"
      },
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "\n",
        "!pip install -qU magenta\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib. \n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "print('Importing libraries and defining some helper functions...')\n",
        "from google.colab import files\n",
        "\n",
        "import magenta\n",
        "import note_seq\n",
        "import tensorflow\n",
        "\n",
        "print('ðŸŽ‰ Done!')\n",
        "print(magenta.__version__)\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing dependencies...\n",
            "Selecting previously unselected package fluid-soundfont-gm.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../fluid-soundfont-gm_3.1-5.1_all.deb ...\n",
            "Unpacking fluid-soundfont-gm (3.1-5.1) ...\n",
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up fluid-soundfont-gm (3.1-5.1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.6MB 3.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 7.2MB/s \n",
            "\u001b[?25h  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 2.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 16.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256kB 17.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 7.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.3MB 17.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 49.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 215kB 53.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 11.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.5MB 47.5MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 358kB 49.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 6.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 49.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 9.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63.8MB 57kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 7.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 215kB 45.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 51.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153kB 52.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 11.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184kB 52.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235kB 51.8MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 440kB 49.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174kB 52.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 10.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307kB 47.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184kB 43.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.3MB 47.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 368kB 51.0MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 9.6MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 655kB 35.3MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 51.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 6.2MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235kB 53.5MB/s \n",
            "\u001b[?25h  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oauth2client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pypng (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pydrive 1.3.1 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.23.0 has requirement dill<0.3.2,>=0.3.1.1, but you'll have dill 0.3.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: apache-beam 2.23.0 has requirement future<1.0.0,>=0.18.2, but you'll have future 0.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensor2tensor 1.15.7 has requirement tensorflow-probability==0.7.0, but you'll have tensorflow-probability 0.11.0 which is incompatible.\u001b[0m\n",
            "Importing libraries and defining some helper functions...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oLSgiA6Uktpm"
      },
      "source": [
        "# Step 1. Making sounds with NoteSequences\n",
        "\n",
        "Everything in `Magenta` is centered around [NoteSequences](https://github.com/magenta/note-seq/blob/master/note_seq/protobuf/music.proto#L27). This is an abstract representation of a series of notes, each with different pitches, instruments and strike velocities, much like [MIDI](https://en.wikipedia.org/wiki/MIDI).\n",
        "\n",
        "For example, this is a `NoteSequence` that represents \"Twinkle Twinkle Little Star\". Try changing the pitches to see how the sound changes!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "71dgCmmBli-s",
        "colab": {}
      },
      "source": [
        "from note_seq.protobuf import music_pb2\n",
        "\n",
        "twinkle_twinkle = music_pb2.NoteSequence()\n",
        "\n",
        "# Add the notes to the sequence.\n",
        "twinkle_twinkle.notes.add(pitch=60, start_time=0.0, end_time=0.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=60, start_time=0.5, end_time=1.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=67, start_time=1.0, end_time=1.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=67, start_time=1.5, end_time=2.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=69, start_time=2.0, end_time=2.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=69, start_time=2.5, end_time=3.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=67, start_time=3.0, end_time=4.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=65, start_time=4.0, end_time=4.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=65, start_time=4.5, end_time=5.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=64, start_time=5.0, end_time=5.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=64, start_time=5.5, end_time=6.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=62, start_time=6.0, end_time=6.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=62, start_time=6.5, end_time=7.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=60, start_time=7.0, end_time=8.0, velocity=80) \n",
        "twinkle_twinkle.total_time = 8\n",
        "\n",
        "twinkle_twinkle.tempos.add(qpm=60);\n",
        "\n",
        "# This is a colab utility method that visualizes a NoteSequence.\n",
        "note_seq.plot_sequence(twinkle_twinkle)\n",
        "\n",
        "# This is a colab utility method that plays a NoteSequence.\n",
        "note_seq.play_sequence(twinkle_twinkle,synth=note_seq.fluidsynth)\n",
        "\n",
        "# Here's another NoteSequence!\n",
        "teapot = music_pb2.NoteSequence()\n",
        "teapot.notes.add(pitch=69, start_time=0, end_time=0.5, velocity=80)\n",
        "teapot.notes.add(pitch=71, start_time=0.5, end_time=1, velocity=80)\n",
        "teapot.notes.add(pitch=73, start_time=1, end_time=1.5, velocity=80)\n",
        "teapot.notes.add(pitch=74, start_time=1.5, end_time=2, velocity=80)\n",
        "teapot.notes.add(pitch=76, start_time=2, end_time=2.5, velocity=80)\n",
        "teapot.notes.add(pitch=81, start_time=3, end_time=4, velocity=80)\n",
        "teapot.notes.add(pitch=78, start_time=4, end_time=5, velocity=80)\n",
        "teapot.notes.add(pitch=81, start_time=5, end_time=6, velocity=80)\n",
        "teapot.notes.add(pitch=76, start_time=6, end_time=8, velocity=80)\n",
        "teapot.total_time = 8\n",
        "\n",
        "teapot.tempos.add(qpm=60);\n",
        "\n",
        "note_seq.plot_sequence(teapot)\n",
        "note_seq.play_sequence(teapot,synth=note_seq.synthesize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oC7BS_4OwCIR"
      },
      "source": [
        "You can use other instruments for your sequences. For example, the sequence below should sound like a drum solo!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQLjca9SwOiI",
        "colab": {}
      },
      "source": [
        "drums = music_pb2.NoteSequence()\n",
        "\n",
        "drums.notes.add(pitch=36, start_time=0, end_time=0.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=38, start_time=0, end_time=0.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=0, end_time=0.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=46, start_time=0, end_time=0.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=0.25, end_time=0.375, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=0.375, end_time=0.5, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=0.5, end_time=0.625, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=50, start_time=0.5, end_time=0.625, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=36, start_time=0.75, end_time=0.875, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=38, start_time=0.75, end_time=0.875, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=0.75, end_time=0.875, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=45, start_time=0.75, end_time=0.875, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=36, start_time=1, end_time=1.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=1, end_time=1.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=46, start_time=1, end_time=1.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=1.25, end_time=1.375, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=48, start_time=1.25, end_time=1.375, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=50, start_time=1.25, end_time=1.375, is_drum=True, instrument=10, velocity=80)\n",
        "drums.total_time = 1.375\n",
        "\n",
        "drums.tempos.add(qpm=60)\n",
        "\n",
        "# This is a colab utility method that visualizes a NoteSequence.\n",
        "note_seq.plot_sequence(drums)\n",
        "\n",
        "# This is a colab utility method that plays a NoteSequence.\n",
        "note_seq.play_sequence(drums,synth=note_seq.fluidsynth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QhtRBNNf05CA"
      },
      "source": [
        "## Converting a `NoteSequence` to MIDI\n",
        "\n",
        "When you called the \"play_sequence\" method above, this converted the `NoteSequence` to MIDI, and created an HTML widget to play it. This method is specially made for colab notebooks, so it won't work inside your Python script. That method uses the Magenta built-in [conversion methods](https://github.com/magenta/note-seq/blob/master/note_seq/midi_io.py#L51), which you can use in your python script:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EcmmAToP4WE3",
        "colab": {}
      },
      "source": [
        "# This creates a file called `drums_sample_output.mid`, containing the drums solo we've been using.\n",
        "note_seq.sequence_proto_to_midi_file(drums, 'drums_sample_output.mid')\n",
        "\n",
        "# This is a colab utility method to download that file. In your Python script, you \n",
        "# would just write it to disk.\n",
        "files.download('drums_sample_output.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9YalOCM_5JP6"
      },
      "source": [
        "## Useful helpers\n",
        "There are a lot of other helper methods sprinkled around the `note_seq` codebase that you might need but not know where to find. Here are some of our favourites:\n",
        "\n",
        "- [converting](https://github.com/magenta/note-seq/blob/master/note_seq/midi_io.py) between MIDI and NoteSequences\n",
        "- [trimming, concatenating and expanding](https://github.com/magenta/note-seq/blob/master/note_seq/sequences_lib.py) NoteSequences\n",
        "- [colab notebook](https://github.com/magenta/note-seq/blob/master/note_seq/notebook_utils.py) utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K1o5dZjR57c_"
      },
      "source": [
        "# Step 2. Using Machine Learning to make music\n",
        "\n",
        "`note_seq` has several Machine Learning models, each with different strengths. All models are built with [Tensorflow](https://www.tensorflow.org), so they will run faster if you can run them on a GPU. Here are some of the most popular ones:\n",
        "\n",
        "- [**MelodyRNN**](https://github.com/magenta/magenta/tree/master/magenta/models/melody_rnn) - you give it a NoteSequence, and it continues it in the style of your original NoteSequence.\n",
        "- [**MusicVAE**](https://github.com/magenta/magenta/tree/master/magenta/models/music_vae) - generates brand new NoteSequences or interpolates between two sequences.\n",
        "- [**Onsets and Frames**](https://github.com/magenta/magenta/tree/master/magenta/models/onsets_frames_transcription) -- transcribes piano audio\n",
        "\n",
        "Now that we know how to use `NoteSequences`, adding some basic Machine Learning is a continuation of that. The pattern for using any of these models is:\n",
        "\n",
        "- Load `note_seq` (which we already know how to do!)\n",
        "- Create a model from a downloaded checkpoint (i.e. where the weights, or the encoding, of the model lives)\n",
        "- Ask the model to do something."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Pm3kdH0-DaH"
      },
      "source": [
        "## Melody RNN\n",
        "\n",
        "A MelodyRNN is an [LSTM-based](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) language model for musical notes -- it is best at continuing a NoteSequence that you give it.\n",
        "\n",
        "To use it, you need to give it a sequence to continue and the model will return the following sequence.\n",
        "\n",
        "This example shows how to use the basic Melody RNN model -- check out the [docs](https://github.com/magenta/magenta/tree/master/magenta/models/melody_rnn) for the other models, such as `lookback_rnn` and `attention_rnn`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zdPBBzSY-P38"
      },
      "source": [
        "### Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Y0VkNafNKLP",
        "colab": {}
      },
      "source": [
        "print('Downloading model bundle. This will take less than a minute...')\n",
        "note_seq.notebook_utils.download_bundle('basic_rnn.mag', '/content/')\n",
        "\n",
        "# Import dependencies.\n",
        "from magenta.models.melody_rnn import melody_rnn_sequence_generator\n",
        "from magenta.models.shared import sequence_generator_bundle\n",
        "from note_seq.protobuf import generator_pb2\n",
        "from note_seq.protobuf import music_pb2\n",
        "\n",
        "# Initialize the model.\n",
        "print(\"Initializing Melody RNN...\")\n",
        "bundle = sequence_generator_bundle.read_bundle_file('/content/basic_rnn.mag')\n",
        "generator_map = melody_rnn_sequence_generator.get_generator_map()\n",
        "melody_rnn = generator_map['basic_rnn'](checkpoint=None, bundle=bundle)\n",
        "melody_rnn.initialize()\n",
        "\n",
        "print('ðŸŽ‰ Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SlYDyTA0-UJT"
      },
      "source": [
        "### Continuing a sequence\n",
        "\n",
        "With Melody RNN, you can configure the number of steps the new sequence will be, as well as the \"temperature\" of the result -- the higher the temperature, the more random (and less like the input) your sequence will be. You can play around with these values and see how the resulting sequences are different:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LgREckzBmd-8",
        "colab": {}
      },
      "source": [
        "# Model options. Change these to get different generated sequences! \n",
        "\n",
        "input_sequence = twinkle_twinkle # change this to teapot if you want\n",
        "num_steps = 128 # change this for shorter or longer sequences\n",
        "temperature = 1.0 # the higher the temperature the more random the sequence.\n",
        "\n",
        "# Set the start time to begin on the next step after the last note ends.\n",
        "last_end_time = (max(n.end_time for n in input_sequence.notes)\n",
        "                  if input_sequence.notes else 0)\n",
        "qpm = input_sequence.tempos[0].qpm \n",
        "seconds_per_step = 60.0 / qpm / melody_rnn.steps_per_quarter\n",
        "total_seconds = num_steps * seconds_per_step\n",
        "\n",
        "generator_options = generator_pb2.GeneratorOptions()\n",
        "generator_options.args['temperature'].float_value = temperature\n",
        "generate_section = generator_options.generate_sections.add(\n",
        "  start_time=last_end_time + seconds_per_step,\n",
        "  end_time=total_seconds)\n",
        "\n",
        "# Ask the model to continue the sequence.\n",
        "sequence = melody_rnn.generate(input_sequence, generator_options)\n",
        "\n",
        "note_seq.plot_sequence(sequence)\n",
        "note_seq.play_sequence(sequence, synth=note_seq.fluidsynth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7zp--0n5FSDm"
      },
      "source": [
        "## Music VAE\n",
        "\n",
        "A [MusicVAE](https://g.co/magenta/musicvae) is a variational autoencoder made up of an Encoder and Decoder -- you can think of the encoder as trying to summarize all the data you give it, and the decoder as trying to recreate the original data, based on this summarized version. As a generative model, you can think of a VAE as coming up with new sequences that could be a decoding of some summarized version.\n",
        "\n",
        "The Music VAE implementation in `magenta/music` in particular does two things: it can create new sequences (which are reconstructions or variations of the input data), or it can interpolate between two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lcx5W1417IP3"
      },
      "source": [
        "### Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "FDW3h0cqUERq",
        "colab": {}
      },
      "source": [
        "print('Copying checkpoint from GCS. This will take less than a minute...')\n",
        "# This will download the mel_2bar_big checkpoint. There are more checkpoints that you\n",
        "# can use with this model, depending on what kind of output you want\n",
        "# See the list of checkpoints: https://github.com/magenta/magenta/tree/master/magenta/models/music_vae#pre-trained-checkpoints\n",
        "!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt.* /content/\n",
        "\n",
        "# Import dependencies.\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "\n",
        "# Initialize the model.\n",
        "print(\"Initializing Music VAE...\")\n",
        "music_vae = TrainedModel(\n",
        "      configs.CONFIG_MAP['cat-mel_2bar_big'], \n",
        "      batch_size=4, \n",
        "      checkpoint_dir_or_path='/content/mel_2bar_big.ckpt')\n",
        "\n",
        "print('ðŸŽ‰ Done!')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "APjD-ph4Fn3Q"
      },
      "source": [
        "### Creating new sequences\n",
        "\n",
        "With Music VAE, you can configure how many new sequences to generate, the number of steps the new sequence will be, as well as the \"temperature\" of the result -- the higher the temperature, the more random (and less like the input) your sequence will be. You can play around with these values and see how the resulting sequences are different:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "XKk8rGihUR6B",
        "colab": {}
      },
      "source": [
        "generated_sequences = music_vae.sample(n=2, length=80, temperature=1.0)\n",
        "\n",
        "for ns in generated_sequences:\n",
        "  # print(ns)\n",
        "  note_seq.plot_sequence(ns)\n",
        "  note_seq.play_sequence(ns, synth=note_seq.fluidsynth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OSq4nJfL-Y2y"
      },
      "source": [
        "### Interpolating between two sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NjHUvtn5-daA",
        "colab": {}
      },
      "source": [
        "# We're going to interpolate between the Twinkle Twinkle Little Star\n",
        "# NoteSequence we defined in the first section, and one of the generated\n",
        "# sequences from the previous VAE example\n",
        "\n",
        "# How many sequences, including the start and end ones, to generate.\n",
        "num_steps = 8;\n",
        "\n",
        "# This gives us a list of sequences.\n",
        "note_sequences = music_vae.interpolate(\n",
        "      twinkle_twinkle,\n",
        "      teapot, \n",
        "      num_steps=num_steps,\n",
        "      length=32)\n",
        "\n",
        "# Concatenate them into one long sequence, with the start and \n",
        "# end sequences at each end. \n",
        "interp_seq = note_seq.sequences_lib.concatenate_sequences(note_sequences)\n",
        "\n",
        "note_seq.play_sequence(interp_seq, synth=note_seq.fluidsynth)\n",
        "note_seq.plot_sequence(interp_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ho6gRbJ4Qgkj"
      },
      "source": [
        "# That's it!\n",
        "\n",
        "You're now ready to build your own amazing, Machine Learning powered, music instrument! If you want more information, you can check out:\n",
        "\n",
        "- some [demos](https://magenta.tensorflow.org/demos) `#MadeWithMagenta`\n",
        "- some more of our [Colab notebooks](https://magenta.tensorflow.org/demos#colab-notebooks)\n",
        "- the [documentation](https://github.com/magenta/magenta)\n",
        "- the [Magenta blog](https://magenta.tensorflow.org/blog), which talks about all the mathy bits we skipped.\n",
        "\n",
        "Have fun! ðŸ’•"
      ]
    }
  ]
}